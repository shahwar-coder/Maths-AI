{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e3d1df",
   "metadata": {},
   "source": [
    "## Part C: Model Training & Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3c9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_c = '''\n",
    "Part C: Model Training & Evaluation\n",
    "\n",
    "• Manual Train-Test Split:\n",
    "  - Shuffle the dataset and split it into training and testing sets (e.g., 80/20).\n",
    "  - Use NumPy operations only; no external libraries for splitting.\n",
    "\n",
    "• Training the Model:\n",
    "  - Run Gradient Descent on the training data.\n",
    "  - Learn optimal weights and bias parameters.\n",
    "\n",
    "• Predictions:\n",
    "  - Use the trained model to make predictions on the test set.\n",
    "  - Convert predicted probabilities into class labels using a threshold (default 0.5).\n",
    "\n",
    "• Evaluation Metrics:\n",
    "  - Manually compute Accuracy, Precision, and Recall.\n",
    "  - Explain why Recall is especially important in cancer detection scenarios.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54820374",
   "metadata": {},
   "source": [
    "### Requirements from previous files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c5f5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Part C: Model Training & Evaluation\n",
    "# Setup & Required Components (Self-Contained)\n",
    "# ============================================================\n",
    "\n",
    "# -------------------------\n",
    "# Imports\n",
    "# -------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Load Dataset\n",
    "# -------------------------\n",
    "df = pd.read_csv(\"Wisconsin.csv\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Separate Features & Target\n",
    "# -------------------------\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target'].values\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Feature Scaling (Min-Max)\n",
    "# -------------------------\n",
    "X_min = X.min()\n",
    "X_max = X.max()\n",
    "X_scaled = (X - X_min) / (X_max - X_min)\n",
    "X_scaled = X_scaled.values  # convert to NumPy array\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Logistic Regression Helpers (from scratch)\n",
    "# -------------------------\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid activation function\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def predict_proba(X, w, b):\n",
    "    \"\"\"Hypothesis function to predict probabilities\"\"\"\n",
    "    z = np.dot(X, w) + b\n",
    "    return sigmoid(z)\n",
    "\n",
    "\n",
    "def compute_cost(y_true, y_pred):\n",
    "    \"\"\"Binary Cross Entropy cost function\"\"\"\n",
    "    m = y_true.shape[0]\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    \n",
    "    cost = -(1 / m) * np.sum(\n",
    "        y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred)\n",
    "    )\n",
    "    return cost\n",
    "\n",
    "\n",
    "def compute_gradients(X, y, y_pred):\n",
    "    \"\"\"Compute gradients for weights and bias\"\"\"\n",
    "    m = X.shape[0]\n",
    "    dw = (1 / m) * np.dot(X.T, (y_pred - y))\n",
    "    db = (1 / m) * np.sum(y_pred - y)\n",
    "    return dw, db\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Setup Summary\n",
    "# -------------------------\n",
    "keep_me_in_loop = '''\n",
    "• Loaded the Breast Cancer dataset for model training and evaluation.\n",
    "• Separated features and target variable.\n",
    "• Applied Min-Max feature scaling manually.\n",
    "• Reimplemented all logistic regression components from scratch.\n",
    "• Prepared a fully self-contained setup for Part C.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a560d33a",
   "metadata": {},
   "source": [
    "### Manual Train-Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5fde125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Manual Train-Test Split (NumPy Only)\n",
    "# ============================================================\n",
    "\n",
    "# Set split ratio\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Number of samples\n",
    "m = X_scaled.shape[0]\n",
    "\n",
    "# Generate shuffled indices\n",
    "indices = np.random.permutation(m)\n",
    "\n",
    "# Compute split index\n",
    "train_size = int(train_ratio * m)\n",
    "\n",
    "# Split indices\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train = X_scaled[train_indices]\n",
    "y_train = y[train_indices]\n",
    "\n",
    "X_test = X_scaled[test_indices]\n",
    "y_test = y[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "435c91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_me_in_loop = '''\n",
    "Here is what we did step by step:\n",
    "\n",
    "1. We decided how much data to use for training and testing.\n",
    "   - We chose 80% for training and 20% for testing using train_ratio = 0.8.\n",
    "\n",
    "2. We found the total number of data samples.\n",
    "   - m = X_scaled.shape[0] gives the number of rows (data points).\n",
    "\n",
    "3. We created a list of numbers from 0 to m−1 and shuffled them randomly.\n",
    "   - This is done using np.random.permutation(m).\n",
    "   - Shuffling helps avoid any order bias in the data.\n",
    "\n",
    "4. We calculated how many samples should go into the training set.\n",
    "   - train_size = int(train_ratio * m).\n",
    "\n",
    "5. We split the shuffled indices into two parts:\n",
    "   - The first part is used for training.\n",
    "   - The remaining part is used for testing.\n",
    "\n",
    "6. Using these indices, we created the actual training data:\n",
    "   - X_train contains the input features for training.\n",
    "   - y_train contains the corresponding output labels.\n",
    "\n",
    "7. Similarly, we created the testing data:\n",
    "   - X_test contains the input features for testing.\n",
    "   - y_test contains the corresponding output labels.\n",
    "\n",
    "8. This method ensures:\n",
    "   - Data is randomly split.\n",
    "   - Training and testing sets do not overlap.\n",
    "   - The model is evaluated fairly on unseen data.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fabae8f",
   "metadata": {},
   "source": [
    "### Training the Model using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e98b16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Training the Logistic Regression Model (Training Set Only)\n",
    "# ============================================================\n",
    "\n",
    "# Initialize parameters\n",
    "m, n = X_train.shape\n",
    "w = np.zeros(n)\n",
    "b = 0.0\n",
    "\n",
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "cost_history = []\n",
    "\n",
    "# Gradient Descent loop\n",
    "for i in range(iterations):\n",
    "    \n",
    "    # Forward propagation\n",
    "    y_pred = predict_proba(X_train, w, b)\n",
    "    \n",
    "    # Compute cost\n",
    "    cost = compute_cost(y_train, y_pred)\n",
    "    cost_history.append(cost)\n",
    "    \n",
    "    # Compute gradients\n",
    "    dw, db = compute_gradients(X_train, y_train, y_pred)\n",
    "    \n",
    "    # Update parameters\n",
    "    w -= learning_rate * dw\n",
    "    b -= learning_rate * db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "700fa1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_me_in_loop = '''\n",
    "Here is what happens during model training step by step:\n",
    "\n",
    "1. We first get the shape of the training data.\n",
    "   - m is the number of training samples (rows).\n",
    "   - n is the number of features (columns).\n",
    "\n",
    "2. We initialize the model parameters:\n",
    "   - w (weights) are set to zeros for all features.\n",
    "   - b (bias) is set to 0.\n",
    "   - This means the model starts with no prior knowledge.\n",
    "\n",
    "3. We choose training settings:\n",
    "   - learning_rate controls how big each update step is.\n",
    "   - iterations decides how many times we repeat training.\n",
    "\n",
    "4. We create an empty list called cost_history.\n",
    "   - This will store the loss value at every iteration.\n",
    "   - It helps us see whether the model is learning.\n",
    "\n",
    "5. We start the Gradient Descent loop.\n",
    "   - The loop runs for the given number of iterations.\n",
    "\n",
    "6. Forward propagation:\n",
    "   - Using the current values of w and b, we predict probabilities\n",
    "     for the training data using predict_proba().\n",
    "   - This gives y_pred (model predictions).\n",
    "\n",
    "7. Cost calculation:\n",
    "   - We compute how wrong the predictions are using compute_cost().\n",
    "   - The cost value is stored in cost_history.\n",
    "\n",
    "8. Gradient calculation:\n",
    "   - We calculate how much w and b should change\n",
    "     using compute_gradients().\n",
    "   - dw is the gradient for weights.\n",
    "   - db is the gradient for bias.\n",
    "\n",
    "9. Parameter update:\n",
    "   - We update w by moving it in the opposite direction of dw.\n",
    "   - We update b by moving it in the opposite direction of db.\n",
    "   - The learning rate controls how large these updates are.\n",
    "\n",
    "10. After many iterations:\n",
    "    - The cost should gradually decrease.\n",
    "    - The model learns the best values of w and b\n",
    "      that minimize the loss on the training data.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf7591",
   "metadata": {},
   "source": [
    "### Predictions on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d2037c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Predictions on Test Set\n",
    "# ============================================================\n",
    "\n",
    "# Predict probabilities on test data\n",
    "y_test_proba = predict_proba(X_test, w, b)\n",
    "\n",
    "# Convert probabilities to class labels using threshold 0.5\n",
    "y_test_pred = (y_test_proba >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6699974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_me_in_loop = '''\n",
    "Here is what we did step by step for predictions on the test set:\n",
    "\n",
    "1. We use the trained model parameters (w and b).\n",
    "   - These values were learned during training using gradient descent.\n",
    "\n",
    "2. We pass the test input data (X_test) into the model.\n",
    "   - predict_proba() calculates the probability of each sample\n",
    "     belonging to the positive class (usually class 1).\n",
    "\n",
    "3. The output y_test_proba contains values between 0 and 1.\n",
    "   - Each value represents how confident the model is\n",
    "     that the sample belongs to class 1.\n",
    "\n",
    "4. We then convert probabilities into actual class labels.\n",
    "   - If probability ≥ 0.5, we predict class 1.\n",
    "   - If probability < 0.5, we predict class 0.\n",
    "\n",
    "5. The comparison (y_test_proba >= 0.5) gives True or False.\n",
    "   - We convert True to 1 and False to 0 using astype(int).\n",
    "\n",
    "6. The final output y_test_pred contains only 0s and 1s.\n",
    "   - These are the predicted class labels for the test data.\n",
    "\n",
    "7. These predictions can now be used to:\n",
    "   - Calculate accuracy\n",
    "   - Build a confusion matrix\n",
    "   - Evaluate how well the model performs on unseen data\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f90aa81",
   "metadata": {},
   "source": [
    "### Evaluation Metrics – Accuracy, Precision, Recall (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16de52d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(35), np.int64(69), np.int64(0), np.int64(10))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Confusion Matrix Components\n",
    "# ============================================================\n",
    "\n",
    "TP = np.sum((y_test == 1) & (y_test_pred == 1))\n",
    "TN = np.sum((y_test == 0) & (y_test_pred == 0))\n",
    "FP = np.sum((y_test == 0) & (y_test_pred == 1))\n",
    "FN = np.sum((y_test == 1) & (y_test_pred == 0))\n",
    "\n",
    "TP, TN, FP, FN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "789f50d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9122807017543859),\n",
       " np.float64(1.0),\n",
       " np.float64(0.7777777777777778))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Evaluation Metrics\n",
    "# ============================================================\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "\n",
    "recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "\n",
    "accuracy, precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dab01349",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_me_in_loop = '''\n",
    "Here is what we did step by step to evaluate the model:\n",
    "\n",
    "1. First, we compare the true labels (y_test) with the predicted labels (y_test_pred).\n",
    "   - This helps us understand how many predictions are correct or wrong.\n",
    "\n",
    "2. We calculate the four parts of the confusion matrix:\n",
    "\n",
    "   a) True Positive (TP):\n",
    "      - The model predicted 1 and the actual value is also 1.\n",
    "      - This means the model correctly identified a positive case.\n",
    "\n",
    "   b) True Negative (TN):\n",
    "      - The model predicted 0 and the actual value is also 0.\n",
    "      - This means the model correctly identified a negative case.\n",
    "\n",
    "   c) False Positive (FP):\n",
    "      - The model predicted 1 but the actual value is 0.\n",
    "      - This means the model gave a false alarm.\n",
    "\n",
    "   d) False Negative (FN):\n",
    "      - The model predicted 0 but the actual value is 1.\n",
    "      - This means the model missed a positive case.\n",
    "\n",
    "3. We then calculate Accuracy:\n",
    "   - Accuracy tells us how many total predictions were correct.\n",
    "   - Formula: (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "4. Next, we calculate Precision:\n",
    "   - Precision tells us how many predicted positives were actually correct.\n",
    "   - Formula: TP / (TP + FP)\n",
    "   - We check if (TP + FP) is not zero to avoid division by zero.\n",
    "\n",
    "5. Then, we calculate Recall:\n",
    "   - Recall tells us how many actual positives were correctly found.\n",
    "   - Formula: TP / (TP + FN)\n",
    "   - We again check if (TP + FN) is not zero.\n",
    "\n",
    "6. Finally, we print Accuracy, Precision, and Recall.\n",
    "   - These values help us understand how well the model performs on test data.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35027df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-maths",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
