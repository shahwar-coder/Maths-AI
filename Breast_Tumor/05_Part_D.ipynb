{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7271188e",
   "metadata": {},
   "source": [
    "## Part D: Business & Healthcare Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b42217",
   "metadata": {},
   "source": [
    "### Setup & Required Inputs (from previous files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735cdf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Part D: Business & Healthcare Insights\n",
    "# Complete Setup (Self-Contained)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------\n",
    "# Load Dataset\n",
    "# -------------------------\n",
    "df = pd.read_csv(\"Wisconsin.csv\")\n",
    "\n",
    "# -------------------------\n",
    "# Separate Features & Target\n",
    "# -------------------------\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"].values\n",
    "feature_names = X.columns\n",
    "\n",
    "# -------------------------\n",
    "# Min-Max Scaling (same as earlier)\n",
    "# -------------------------\n",
    "X_min = X.min()\n",
    "X_max = X.max()\n",
    "X_scaled = (X - X_min) / (X_max - X_min)\n",
    "X_scaled = X_scaled.values\n",
    "\n",
    "# -------------------------\n",
    "# Logistic Regression Helpers\n",
    "# -------------------------\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def predict_proba(X, w, b):\n",
    "    return sigmoid(np.dot(X, w) + b)\n",
    "\n",
    "def compute_gradients(X, y, y_pred):\n",
    "    m = X.shape[0]\n",
    "    dw = (1 / m) * np.dot(X.T, (y_pred - y))\n",
    "    db = (1 / m) * np.sum(y_pred - y)\n",
    "    return dw, db\n",
    "\n",
    "# -------------------------\n",
    "# Train Model (ONLY to get weights)\n",
    "# -------------------------\n",
    "m, n = X_scaled.shape\n",
    "w = np.zeros(n)\n",
    "b = 0.0\n",
    "\n",
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "for _ in range(iterations):\n",
    "    y_pred = predict_proba(X_scaled, w, b)\n",
    "    dw, db = compute_gradients(X_scaled, y, y_pred)\n",
    "    w -= learning_rate * dw\n",
    "    b -= learning_rate * db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226caeb1",
   "metadata": {},
   "source": [
    "### Feature Importance (Analyzing Learned Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd23466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Abs_Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean concave points</td>\n",
       "      <td>0.399610</td>\n",
       "      <td>0.399610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>worst concave points</td>\n",
       "      <td>0.395593</td>\n",
       "      <td>0.395593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean concavity</td>\n",
       "      <td>0.347909</td>\n",
       "      <td>0.347909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>worst perimeter</td>\n",
       "      <td>0.284475</td>\n",
       "      <td>0.284475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>worst radius</td>\n",
       "      <td>0.283615</td>\n",
       "      <td>0.283615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>worst area</td>\n",
       "      <td>0.264707</td>\n",
       "      <td>0.264707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>worst concavity</td>\n",
       "      <td>0.262888</td>\n",
       "      <td>0.262888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean area</td>\n",
       "      <td>0.234886</td>\n",
       "      <td>0.234886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean fractal dimension</td>\n",
       "      <td>-0.231061</td>\n",
       "      <td>0.231061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean perimeter</td>\n",
       "      <td>0.212819</td>\n",
       "      <td>0.212819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature    Weight  Abs_Weight\n",
       "7      mean concave points  0.399610    0.399610\n",
       "27    worst concave points  0.395593    0.395593\n",
       "6           mean concavity  0.347909    0.347909\n",
       "22         worst perimeter  0.284475    0.284475\n",
       "20            worst radius  0.283615    0.283615\n",
       "23              worst area  0.264707    0.264707\n",
       "26         worst concavity  0.262888    0.262888\n",
       "3                mean area  0.234886    0.234886\n",
       "9   mean fractal dimension -0.231061    0.231061\n",
       "2           mean perimeter  0.212819    0.212819"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Feature Importance Analysis\n",
    "# ============================================================\n",
    "\n",
    "# Create a DataFrame of features and their learned weights\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Weight\": w\n",
    "})\n",
    "\n",
    "# Sort features by absolute weight (importance)\n",
    "feature_importance[\"Abs_Weight\"] = feature_importance[\"Weight\"].abs()\n",
    "feature_importance = feature_importance.sort_values(\n",
    "    by=\"Abs_Weight\", ascending=False\n",
    ")\n",
    "\n",
    "# Display top important features\n",
    "feature_importance.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204a94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_me_in_loop = '''\n",
    "Here is what we did step by step to analyze feature importance:\n",
    "\n",
    "1. After training the model, we already have learned weights (w).\n",
    "   - Each weight corresponds to one input feature.\n",
    "   - The value of the weight shows how important that feature is.\n",
    "\n",
    "2. We create a table (DataFrame) using pandas.\n",
    "   - One column stores feature names.\n",
    "   - Another column stores the learned weights for each feature.\n",
    "\n",
    "3. Each weight can be positive or negative:\n",
    "   - Positive weight means the feature increases the chance of class 1.\n",
    "   - Negative weight means the feature decreases the chance of class 1.\n",
    "\n",
    "4. To measure importance, we take the absolute value of each weight.\n",
    "   - Absolute value ignores the sign and keeps only the strength.\n",
    "   - Bigger absolute value means more influence on the prediction.\n",
    "\n",
    "5. We store these absolute values in a new column called \"Abs_Weight\".\n",
    "\n",
    "6. We sort the table in descending order using \"Abs_Weight\".\n",
    "   - This brings the most important features to the top.\n",
    "\n",
    "7. Finally, we display the top 10 features.\n",
    "   - These are the features that most strongly affect the model’s decision.\n",
    "\n",
    "8. This analysis helps us:\n",
    "   - Understand which features matter the most.\n",
    "   - Explain model behavior instead of treating it like a black box.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67783ae5",
   "metadata": {},
   "source": [
    "### Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbaff1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_interpretation = '''\n",
    "Model Interpretation:\n",
    "\n",
    "• The logistic regression model predicts the probability that a breast tumor is malignant.\n",
    "• The output of the model is a value between 0 and 1.\n",
    "• This value represents the model’s confidence in its prediction.\n",
    "\n",
    "• For example:\n",
    "  - A prediction of 0.90 means the model estimates a 90% chance that the tumor is malignant.\n",
    "  - A prediction of 0.20 means the model estimates a 20% chance of malignancy.\n",
    "\n",
    "• A decision threshold (typically 0.5) is used to convert probabilities into class labels:\n",
    "  - Probability ≥ 0.5 → Malignant\n",
    "  - Probability < 0.5 → Benign\n",
    "\n",
    "• The model does not replace doctors.\n",
    "• Instead, it acts as a decision-support tool that helps prioritize high-risk cases.\n",
    "• This allows doctors to focus attention on suspicious biopsies more quickly.\n",
    "\n",
    "• The confidence scores help clinicians understand how strongly the model believes its prediction,\n",
    "  supporting informed medical judgment.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4603b601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-maths",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
