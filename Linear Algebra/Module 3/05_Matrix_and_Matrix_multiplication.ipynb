{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662af50d",
   "metadata": {},
   "source": [
    "### Matrix and Matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e87f65",
   "metadata": {},
   "source": [
    "### Set-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "417e7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SET‚Äì1 : Matrix √ó Matrix Multiplication (Foundations & Intuition)\n",
    "\n",
    "Q1. What does matrix √ó matrix multiplication mean in simple words?\n",
    "Ans. It means applying one matrix transformation to many vectors at once.\n",
    "'''\n",
    "# Example\n",
    "# Matrix √ó vector = one transformation\n",
    "# Matrix √ó matrix = many such transformations together\n",
    "\n",
    "\n",
    "'''\n",
    "Q2. What is the shape rule for matrix √ó matrix multiplication?\n",
    "Ans. The number of columns in the first matrix must equal the number of rows in the second.\n",
    "'''\n",
    "# Example\n",
    "# A shape = (m, n)\n",
    "# B shape = (n, p)\n",
    "# A √ó B   = (m, p)\n",
    "\n",
    "\n",
    "'''\n",
    "Q3. Why must the inner dimensions match?\n",
    "Ans. Because each row of the first matrix must align with each column of the second matrix.\n",
    "'''\n",
    "# Example\n",
    "# (2, 3) √ó (3, 2) ‚Üí valid\n",
    "# (2, 3) √ó (4, 2) ‚Üí ‚ùå invalid\n",
    "\n",
    "\n",
    "'''\n",
    "Q4. How is each element of the result matrix computed?\n",
    "Ans. Each element is the dot product of one row from A and one column from B.\n",
    "'''\n",
    "# Example\n",
    "row_A    = [1, 2, 3]\n",
    "column_B = [7, 9, 11]\n",
    "# Dot product = 1*7 + 2*9 + 3*11 = 58\n",
    "\n",
    "\n",
    "'''\n",
    "Q5. What is the step-by-step meaning of matrix multiplication?\n",
    "Ans. For each row of A and each column of B, compute a dot product.\n",
    "'''\n",
    "# Example\n",
    "A = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "]\n",
    "B = [\n",
    "    [7,  8],\n",
    "    [9, 10],\n",
    "    [11,12]\n",
    "]\n",
    "# Result shape = (2, 2)\n",
    "\n",
    "\n",
    "'''\n",
    "Q6. How can matrix √ó matrix be seen as many matrix √ó vector operations?\n",
    "Ans. Each column of B is treated as a vector and multiplied by A.\n",
    "'''\n",
    "# Example\n",
    "# A √ó B = [A¬∑b1 | A¬∑b2]\n",
    "# where b1 and b2 are columns of B\n",
    "\n",
    "\n",
    "q='''\n",
    "Q7. Why does matrix multiplication order matter?\n",
    "Ans. Because row‚Äìcolumn alignment changes when order is reversed.\n",
    "'''\n",
    "# Example\n",
    "# A √ó B ‚â† B √ó A\n",
    "# Shapes and results are different\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d48b648",
   "metadata": {},
   "source": [
    "#### Set-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7ce6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SET‚Äì2 : Matrix √ó Matrix Multiplication (AI & Practical Usage)\n",
    "\n",
    "Q1. Why is matrix √ó matrix multiplication essential in machine learning?\n",
    "Ans. Because it transforms entire datasets in one operation.\n",
    "'''\n",
    "# Example\n",
    "# X (N, D) √ó W (D, H) ‚Üí Output (N, H)\n",
    "\n",
    "\n",
    "'''\n",
    "Q2. How does matrix multiplication represent a neural network layer?\n",
    "Ans. Each column of the weight matrix represents one neuron applied to all samples.\n",
    "'''\n",
    "# Example\n",
    "# Each column in W produces one output feature\n",
    "\n",
    "\n",
    "'''\n",
    "Q3. How does matrix √ó matrix multiplication relate to embeddings?\n",
    "Ans. It projects embeddings into new spaces like queries, keys, and values.\n",
    "'''\n",
    "# Example\n",
    "# E √ó Wq ‚Üí query embeddings\n",
    "# E √ó Wk ‚Üí key embeddings\n",
    "# E √ó Wv ‚Üí value embeddings\n",
    "\n",
    "\n",
    "'''\n",
    "Q4. Why is matrix multiplication not commutative?\n",
    "Ans. Because rows and columns play different roles in the operation.\n",
    "'''\n",
    "# Example\n",
    "# A shape = (2, 3)\n",
    "# B shape = (3, 2)\n",
    "# A √ó B exists, but B √ó A gives a different result\n",
    "\n",
    "\n",
    "'''\n",
    "Q5. What is a common beginner mistake in matrix √ó matrix multiplication?\n",
    "Ans. Confusing it with element-wise multiplication.\n",
    "'''\n",
    "# Example\n",
    "# A * B ‚Üí element-wise (different operation)\n",
    "# A √ó B ‚Üí row‚Äìcolumn dot products\n",
    "\n",
    "\n",
    "'''\n",
    "Q6. How does matrix multiplication enable parallel computation on GPUs?\n",
    "Ans. Each row‚Äìcolumn dot product is independent and can be computed in parallel.\n",
    "'''\n",
    "# Example\n",
    "# Thousands of dot products computed simultaneously\n",
    "\n",
    "\n",
    "q='''\n",
    "Q7. What is the key mental rule to remember?\n",
    "Ans. Row of first matrix talks to column of second matrix using dot product.\n",
    "'''\n",
    "# Example\n",
    "# (A √ó B)[i][j] = row_i(A) ¬∑ column_j(B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1959ee",
   "metadata": {},
   "source": [
    "### Matrix x Vector VS Matrix x Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930bad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17]\n",
      " [39]]\n",
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Matrix √ó vector (single vector)\n",
    "A = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "x = np.array([[5],\n",
    "              [6]])\n",
    "\n",
    "print(A @ x)\n",
    "\n",
    "# Matrix √ó matrix (many vectors at once)\n",
    "B = np.array([[5, 6],\n",
    "              [7, 8]])\n",
    "\n",
    "print(A @ B)\n",
    "\n",
    "# Matrix √ó matrix = batch version of matrix √ó vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e557cda",
   "metadata": {},
   "source": [
    "### Observe Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bdf1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "A = np.random.rand(2, 3)\n",
    "B = np.random.rand(3, 4)\n",
    "\n",
    "C = A @ B\n",
    "print(C.shape)   # (2, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1349fd",
   "metadata": {},
   "source": [
    "### Why inner dimensions must match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db160488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90250314, 0.71764131],\n",
       "       [0.69751942, 0.73000733]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valid\n",
    "np.random.rand(2, 3) @ np.random.rand(3, 2)\n",
    "\n",
    "# Invalid\n",
    "# np.random.rand(2, 3) @ np.random.rand(4, 2)\n",
    "\n",
    "# Dot products require equal-length vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc36729",
   "metadata": {},
   "source": [
    "### At a small level : How each element is Computed ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7470ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "row_A    = np.array([1, 2, 3])\n",
    "column_B = np.array([7, 9, 11])\n",
    "\n",
    "print(row_A @ column_B)   # 58\n",
    "\n",
    "# Operation of One row and One column YIELDS One value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb556959",
   "metadata": {},
   "source": [
    "### Individual Calculation is Independent (Important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9674664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 39]\n",
      "[23 53]\n",
      "[[17 23]\n",
      " [39 53]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 1: Define matrices A and B\n",
    "# --------------------------------------------------\n",
    "# A is a transformation matrix\n",
    "A = np.array([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "# B is a matrix containing MULTIPLE vectors\n",
    "# Each column of B is one vector\n",
    "B = np.array([\n",
    "    [5,  7],\n",
    "    [6,  8]\n",
    "])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 2: Understand what matrix √ó matrix means\n",
    "# --------------------------------------------------\n",
    "# A @ B does NOT mix columns together.\n",
    "# Instead:\n",
    "# - Take ONE column of B\n",
    "# - Apply A to it (matrix √ó vector)\n",
    "# - Repeat independently for each column\n",
    "#\n",
    "# `Matrix √ó Matrix` = many `Matrix √ó Vector` operations\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 3: Extract columns of B (vectors)\n",
    "# --------------------------------------------------\n",
    "b1 = B[:, 0]   # First column of B\n",
    "b2 = B[:, 1]   # Second column of B\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 4: Apply A to each vector independently\n",
    "# --------------------------------------------------\n",
    "out1 = A @ b1\n",
    "out2 = A @ b2\n",
    "\n",
    "print(out1)\n",
    "print(out2)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 5: Stack the results to form final matrix\n",
    "# --------------------------------------------------\n",
    "# The final result of A @ B is just:\n",
    "# [ A@b1 , A@b2 ] as columns\n",
    "result = np.column_stack([out1, out2])\n",
    "\n",
    "print(result)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# KEY CONCEPT (MOST IMPORTANT PART)\n",
    "# --------------------------------------------------\n",
    "# Each column is transformed independently\n",
    "# No column affects another column\n",
    "# Same transformation (A) is applied every time\n",
    "#\n",
    "# Think of it like:\n",
    "# - B holds multiple input vectors\n",
    "# - A is a machine\n",
    "# - Each vector goes through the machine separately\n",
    "#\n",
    "# Final shape rule:\n",
    "# (m, n) @ (n, k) ‚Üí (m, k)\n",
    "#\n",
    "# k independent transformations happen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928098ee",
   "metadata": {},
   "source": [
    "### Example: Embedding and Projection (Read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbccf88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187.88881781 198.18904425 195.83182058 ... 194.35469802 197.22938863\n",
      "  195.32680526]\n",
      " [182.30784534 187.20167675 187.55886894 ... 187.0638015  187.12241008\n",
      "  187.20223914]\n",
      " [190.42128291 193.2108744  195.17468294 ... 185.61181384 192.04614823\n",
      "  190.07780693]\n",
      " ...\n",
      " [190.59113198 195.38054791 193.91091685 ... 195.87723076 195.27344619\n",
      "  192.05958177]\n",
      " [182.30901371 194.12049983 193.17827976 ... 186.43794409 194.69623906\n",
      "  193.04994271]\n",
      " [183.56434911 186.39175267 185.44567483 ... 178.59677953 185.55858163\n",
      "  182.24992439]]\n",
      "(32, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 1: Embeddings matrix (E)\n",
    "# --------------------------------------------------\n",
    "# Think of E as a batch of token embeddings.\n",
    "#\n",
    "# Shape: (32, 768)\n",
    "# - 32   ‚Üí number of tokens (or samples)\n",
    "# - 768  ‚Üí embedding dimension (original semantic space)\n",
    "#\n",
    "# Each ROW is ONE token embedding.\n",
    "# Each row is processed independently.\n",
    "E = np.random.rand(32, 768)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 2: Projection matrix (Wq)\n",
    "# --------------------------------------------------\n",
    "# Wq is a learned weight matrix.\n",
    "#\n",
    "# Shape: (768, 64)\n",
    "# - Input size  = 768\n",
    "# - Output size = 64\n",
    "#\n",
    "# This matrix defines HOW we want to \"look at\" embeddings.\n",
    "# It decides what information to keep, compress, or ignore.\n",
    "Wq = np.random.rand(768, 64)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 3: Matrix multiplication (Projection)\n",
    "# --------------------------------------------------\n",
    "# We project embeddings into a NEW space.\n",
    "#\n",
    "# (32, 768) @ (768, 64) ‚Üí (32, 64)\n",
    "#\n",
    "# What actually happens:\n",
    "# - Take ONE embedding vector (row of E)\n",
    "# - Multiply it with Wq\n",
    "# - Produce ONE new vector of size 64\n",
    "# - Repeat this independently for all 32 rows\n",
    "Q = E @ Wq\n",
    "print(Q)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 4: Result shape\n",
    "# --------------------------------------------------\n",
    "print(Q.shape)   # (32, 64)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# KEY CONCEPTUAL TAKEAWAYS (MOST IMPORTANT)\n",
    "# --------------------------------------------------\n",
    "# Each embedding (row) is projected independently\n",
    "# No token mixes with another token here\n",
    "# Same projection matrix (Wq) is applied to every row\n",
    "#\n",
    "# You can think of Wq as:\n",
    "# - A \"lens\"\n",
    "# - A \"view\"\n",
    "# - A rule for re-expressing meaning\n",
    "#\n",
    "# Original space: 768-dim (general meaning)\n",
    "# New space:       64-dim (query-specific meaning)\n",
    "#\n",
    "# This is why we call it:\n",
    "# üëâ \"Projection into a new semantic space\"\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# ATTENTION CONTEXT (VERY IMPORTANT)\n",
    "# --------------------------------------------------\n",
    "# In self-attention:\n",
    "# - E @ Wq ‚Üí Queries\n",
    "# - E @ Wk ‚Üí Keys\n",
    "# - E @ Wv ‚Üí Values\n",
    "#\n",
    "# SAME embeddings\n",
    "# DIFFERENT projection matrices\n",
    "# DIFFERENT semantic roles\n",
    "#\n",
    "# Final mental model:\n",
    "# Many vectors ‚Üí same transformation ‚Üí independent projections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4301ce63",
   "metadata": {},
   "source": [
    "### Read (Embedding & Projections)\n",
    "#### A Mental Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bc51ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL SIMPLE MENTAL MODEL\n",
    "# ------------------------\n",
    "\n",
    "# Imagine ONE token embedding\n",
    "# This is ONE row from E\n",
    "# It is just a list of numbers describing the token\n",
    "'''\n",
    "e = [e1, e2, e3, ..., e768]   # shape = (768,)\n",
    "'''\n",
    "\n",
    "# Think of this as:\n",
    "# \"All information the model knows about this token\"\n",
    "\n",
    "\n",
    "# Now imagine ONE column from Wq\n",
    "# This column is ONE learned direction\n",
    "# It decides what kind of information we want to look at\n",
    "'''\n",
    "w = [w1, w2, w3, ..., w768]   # shape = (768,)\n",
    "'''\n",
    "\n",
    "# Think of this as:\n",
    "# \"Which parts of the token matter for THIS question?\"\n",
    "\n",
    "\n",
    "# DOT PRODUCT (most important step)\n",
    "# --------------------------------\n",
    "# We multiply matching numbers and add them\n",
    "'''\n",
    "score = (e1*w1) + (e2*w2) + (e3*w3) + ... + (e768*w768)\n",
    "'''\n",
    "\n",
    "# Result:\n",
    "# ‚úî ONE number\n",
    "# ‚úî This number answers ONE question about the token\n",
    "\n",
    "\n",
    "# WHAT DOES THIS NUMBER MEAN?\n",
    "# ---------------------------\n",
    "# Big value  ‚Üí token strongly matches this question\n",
    "# Small value ‚Üí token weakly matches this question\n",
    "\n",
    "# This is called a PROJECTION\n",
    "# We are projecting the token onto ONE direction\n",
    "\n",
    "\n",
    "# FULL PROJECTION\n",
    "# ---------------\n",
    "# Wq has MANY columns (64 of them)\n",
    "# Each column asks a DIFFERENT question\n",
    "\n",
    "# So we repeat the same dot product 64 times\n",
    "'''\n",
    "q = [score1, score2, score3, ..., score64]   # shape = (64,)\n",
    "'''\n",
    "\n",
    "# This is the new representation of the token\n",
    "# Same token, but viewed differently\n",
    "\n",
    "\n",
    "# BATCH VERSION\n",
    "# -------------\n",
    "# When we do:\n",
    "'''\n",
    "Q = E @ Wq\n",
    "'''\n",
    "#\n",
    "# This means:\n",
    "# - Take each token one by one\n",
    "# - Ask the same 64 questions\n",
    "# - Do NOT mix tokens\n",
    "# - Everything is independent\n",
    "\n",
    "\n",
    "# ONE-LINE MEMORY RULE (IMPORTANT)\n",
    "# -------------------------------\n",
    "# Each column of Wq is a question.\n",
    "# Each dot product is the answer.\n",
    "\n",
    "imp_mental_model = 'above'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ab933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-maths",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
