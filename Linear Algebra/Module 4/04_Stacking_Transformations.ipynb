{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68652894",
   "metadata": {},
   "source": [
    "### Stacking Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Stacking Transformations\n",
    "\n",
    "Q1. What does stacking transformations mean in deep learning?\n",
    "Ans. Stacking transformations means applying many small transformations one after another, where each layer slightly changes the input.\n",
    "'''\n",
    "# Example\n",
    "# Input â†’ Layer 1 (small change) â†’ Layer 2 (small change) â†’ Layer 3 â†’ Output\n",
    "\n",
    "\n",
    "'''\n",
    "Q2. Why is stacking many small transformations more powerful than one big transformation?\n",
    "Ans. Because many small changes can gradually reshape space into complex forms that a single transformation cannot achieve.\n",
    "'''\n",
    "# Example\n",
    "# One stretch â†’ small effect\n",
    "# Stretch + rotate + shear + stretch â†’ very different final shape\n",
    "\n",
    "\n",
    "'''\n",
    "Q3. What is the visual intuition behind stacking transformations?\n",
    "Ans. Space behaves like a soft rubber sheet that gets bent, stretched, and twisted repeatedly by each layer.\n",
    "'''\n",
    "# Example\n",
    "# Layer 1: stretch space\n",
    "# Layer 2: rotate stretched space\n",
    "# Layer 3: shear rotated space\n",
    "\n",
    "\n",
    "'''\n",
    "Q4. How are stacked transformations represented conceptually using matrices?\n",
    "Ans. Each layer has a matrix, and stacking layers corresponds to multiplying these matrices in sequence.\n",
    "'''\n",
    "# Example\n",
    "# v â†’ A1 â†’ A2 â†’ A3\n",
    "# Equivalent to: A3 Ã— A2 Ã— A1 Ã— v\n",
    "\n",
    "\n",
    "'''\n",
    "Q5. Why does depth help neural networks learn complex patterns?\n",
    "Ans. Because deeper networks can create rich, hierarchical representations by repeatedly transforming feature space.\n",
    "'''\n",
    "# Example\n",
    "# Early layers: edges\n",
    "# Middle layers: shapes\n",
    "# Deep layers: objects or meaning\n",
    "\n",
    "\n",
    "'''\n",
    "Q6. What happens if we stack only linear transformations?\n",
    "Ans. All linear transformations collapse into a single linear transformation, limiting expressiveness.\n",
    "'''\n",
    "# Example\n",
    "# A Ã— B Ã— C = D (still linear)\n",
    "\n",
    "\n",
    "q='''\n",
    "Q7. Why are non-linearities necessary when stacking transformations?\n",
    "Ans. Non-linearities prevent collapse into a single transformation and allow networks to model complex, non-linear relationships.\n",
    "'''\n",
    "# Example\n",
    "# Linear â†’ Linear â†’ Linear = Linear\n",
    "# Linear â†’ ReLU â†’ Linear = Non-linear power\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5b04a7",
   "metadata": {},
   "source": [
    "### Stacking Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649a32ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. ]\n",
      " [ 1.1]]\n"
     ]
    }
   ],
   "source": [
    "# Applying many small transformations one after another.\n",
    "\n",
    "import numpy as np\n",
    "x = np.array([[1],\n",
    "              [1]])\n",
    "W1 = np.array([[1.1, 0.0],\n",
    "               [0.0, 1.0]])\n",
    "W2 = np.array([[0.0, -1.0],\n",
    "               [1.0,  0.0]])\n",
    "y = W2 @ (W1 @ x)\n",
    "print(y)\n",
    "\n",
    "# ðŸ“Œ Each layer slightly changes the representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02681ab",
   "metadata": {},
   "source": [
    "### Why many small > one big? (Transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48be4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradual reshaping allows complex geometry.\n",
    "# One matrix â†’ limited shape change\n",
    "# Many matrices â†’ progressive bending of space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d2db0",
   "metadata": {},
   "source": [
    "### Stacking Layers and Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b273a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking layers = multiplying matrices in sequence.\n",
    "\n",
    "# Apply A1, then A2, then A3\n",
    "# y = A3 @ A2 @ A1 @ x\n",
    "\n",
    "# ðŸ“Œ Read right to left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a746498",
   "metadata": {},
   "source": [
    "### Why are NON-LINEARITIES important in Neural Networks ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efa478",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "1. Linear layers:\n",
    "   â€¢ stretch, rotate, and shift data\n",
    "   â€¢ always keep space flat\n",
    "\n",
    "2. Stacking linear layers:\n",
    "   Linear â†’ Linear â†’ Linear\n",
    "   â€¢ collapses into ONE linear transformation\n",
    "   â€¢ adds no extra learning power\n",
    "\n",
    "3. Problem:\n",
    "   â€¢ real-world data is curved and complex\n",
    "   â€¢ linear models can only make straight-line decisions\n",
    "\n",
    "4. Non-linearity (e.g., ReLU):\n",
    "   â€¢ bends and folds the space\n",
    "   â€¢ breaks linear collapse\n",
    "\n",
    "5. With non-linearity:\n",
    "   Linear â†’ ReLU â†’ Linear\n",
    "   â€¢ becomes a truly non-linear function\n",
    "   â€¢ allows curved decision boundaries\n",
    "\n",
    "6. Result:\n",
    "   â€¢ networks gain expressive power\n",
    "   â€¢ deep learning becomes possible\n",
    "\n",
    "Final rule:\n",
    "Linear layers move space.\n",
    "Non-linearities reshape space.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ecd55f",
   "metadata": {},
   "source": [
    "### Bending Space = Complex Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6854509",
   "metadata": {},
   "outputs": [],
   "source": [
    "bending_space = '''\n",
    "Bending space = complex learning (visual intuition)\n",
    "\n",
    "1. Matrix (linear layer):\n",
    "   â€¢ stretches, rotates, shifts points\n",
    "   â€¢ keeps space flat\n",
    "   â€¢ straight lines stay straight\n",
    "\n",
    "2. Stacking matrices:\n",
    "   â€¢ collapses into one linear transform\n",
    "   â€¢ no added learning power\n",
    "\n",
    "3. ReLU (non-linearity):\n",
    "   â€¢ cuts space at 0 (bends here)\n",
    "   â€¢ flattens one side\n",
    "   â€¢ introduces bends and corners\n",
    "\n",
    "4. Effect of ReLU:\n",
    "   â€¢ space is no longer smooth\n",
    "   â€¢ creates folds in data\n",
    "   â€¢ enables curved decision boundaries\n",
    "\n",
    "5. Matrix + ReLU together:\n",
    "   â€¢ matrix positions points\n",
    "   â€¢ ReLU bends space\n",
    "   â€¢ repetition increases complexity\n",
    "\n",
    "Final intuition:\n",
    "Matrices move space.\n",
    "ReLU bends space.\n",
    "Bending space = learning complex patterns.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26182e69",
   "metadata": {},
   "source": [
    "### Glance at ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bafa3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = '''\n",
    "ReLU (explained very simply)\n",
    "\n",
    "1. What ReLU does:\n",
    "   â€¢ looks at a number\n",
    "   â€¢ if number < 0 â†’ make it 0\n",
    "   â€¢ if number â‰¥ 0 â†’ keep it\n",
    "\n",
    "2. Simple rule:\n",
    "   ReLU = \"no negatives allowed\"\n",
    "\n",
    "3. Visual idea:\n",
    "   â€¢ left side (negative) â†’ flattened to zero\n",
    "   â€¢ right side (positive) â†’ stays as it is\n",
    "\n",
    "4. Why this matters:\n",
    "   â€¢ space is no longer smooth\n",
    "   â€¢ a sharp corner appears at 0\n",
    "   â€¢ this is called a \"bend\"\n",
    "\n",
    "5. What this helps with:\n",
    "   â€¢ straight lines can turn\n",
    "   â€¢ simple shapes become complex\n",
    "   â€¢ model can learn harder patterns\n",
    "\n",
    "Final intuition:\n",
    "Matrix = move points\n",
    "ReLU = block negatives\n",
    "Blocking negatives = bending space\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-maths",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
